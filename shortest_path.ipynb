{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pqdict import PQDict\n",
      "import gdist\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as stats\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from mayavi import mlab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_vtk(file):\n",
      "    # read full file while dropping empty lines \n",
      "    vtk_df=pd.read_csv(file, header=None)\n",
      "    vtk_df=vtk_df.dropna()\n",
      "    # extract number of vertices and faces\n",
      "    number_vertices=int(vtk_df[vtk_df[0].str.contains('POINTS')][0].iloc[0].split()[1])\n",
      "    number_faces=int(vtk_df[vtk_df[0].str.contains('POLYGONS')][0].iloc[0].split()[1])\n",
      "    # read vertices into df and array\n",
      "    start_vertices= (vtk_df[vtk_df[0].str.contains('POINTS')].index.tolist()[0])+1\n",
      "    vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=number_vertices, sep='\\s*', header=None)\n",
      "    if np.array(vertex_df).shape[1]==3:\n",
      "        vertex_array=np.array(vertex_df)\n",
      "    # sometimes the vtk format is weird with 9 indices per line, then it has to be reshaped\n",
      "    elif np.array(vertex_df).shape[1]==9:\n",
      "        vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=number_vertices/3+1, sep='\\s*', header=None)\n",
      "        vertex_array=np.array(vertex_df.iloc[0:1,0:3])\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,3:6], axis=0)\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,6:9], axis=0)\n",
      "        for row in range(1,(number_vertices/3+1)):\n",
      "            for col in [0,3,6]:\n",
      "                vertex_array=np.append(vertex_array, array(vertex_df.iloc[row:(row+1),col:(col+3)]),axis=0) \n",
      "        # strip rows containing nans\n",
      "        vertex_array=vertex_array[ ~np.isnan(vertex_array) ].reshape(number_vertices,3)\n",
      "    else:\n",
      "        print \"vertex indices out of shape\"\n",
      "    vertices = {'val' : vertex_array, 'number' : number_vertices}\n",
      "    # read faces into df and array\n",
      "    start_faces= (vtk_df[vtk_df[0].str.contains('POLYGONS')].index.tolist()[0])+1\n",
      "    face_df=pd.read_csv(file, skiprows=range(start_faces), nrows=number_faces, sep='\\s*', header=None)\n",
      "    face_array=np.array(face_df.iloc[:,1:4])\n",
      "    faces = {'val' : face_array, 'number' : number_faces}\n",
      "    # read data into df and array\n",
      "    start_data= (vtk_df[vtk_df[0].str.contains('POINT_DATA')].index.tolist()[0])+3\n",
      "    number_data = number_vertices\n",
      "    data_df=pd.read_csv(file, skiprows=range(start_data), nrows=number_data, sep='\\s*', header=None)\n",
      "    data_array=np.array(data_df)\n",
      "    data = {'val' : data_array, 'number' : number_data}\n",
      "    \n",
      "    return vertices, faces, data\n",
      "\n",
      "#TO DO: add reading comments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "https://github.com/joyrexus/dijkstra/blob/master/dijkstra.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dijkstra(G, start, end=None):\n",
      "    '''\n",
      "    dijkstra's algorithm determines the length from `start` to every other \n",
      "    vertex in the graph.\n",
      "    The graph argument `G` should be a dict indexed by nodes.  The value \n",
      "    of each item `G[v]` should also a dict indexed by successor nodes.\n",
      "    In other words, for any node `v`, `G[v]` is itself a dict, indexed \n",
      "    by the successors of `v`.  For any directed edge `v -> w`, `G[v][w]` \n",
      "    is the length of the edge from `v` to `w`.\n",
      "        graph = {'a': {'b': 1}, \n",
      "                 'b': {'c': 2, 'b': 5}, \n",
      "                 'c': {'d': 1},\n",
      "                 'd': {}}\n",
      "    Returns two dicts, `dist` and `pred`:\n",
      "        dist, pred = dijkstra(graph, start='a') \n",
      "    \n",
      "    `dist` is a dict mapping each node to its shortest distance from the\n",
      "    specified starting node:\n",
      "        assert dist == {'a': 0, 'c': 3, 'b': 1, 'd': 4}\n",
      "    `pred` is a dict mapping each node to its predecessor node on the\n",
      "    shortest path from the specified starting node:\n",
      "        assert pred == {'b': 'a', 'c': 'b', 'd': 'c'}\n",
      "    \n",
      "    '''\n",
      "    inf = float('inf')\n",
      "    D = {start: 0}          # mapping of nodes to their dist from start\n",
      "    Q = PQDict(D)           # priority queue for tracking min shortest path\n",
      "    P = {}                  # mapping of nodes to their direct predecessors\n",
      "    U = set(G.keys())       # unexplored nodes\n",
      "\n",
      "    while U:                                    # nodes yet to explore\n",
      "        (v, d) = Q.popitem()                    # node w/ min dist d on frontier\n",
      "        D[v] = d                                # est dijkstra greedy score\n",
      "        U.remove(v)                             # remove from unexplored\n",
      "        if v == end: break\n",
      "\n",
      "        # now consider the edges from v with an unexplored head -\n",
      "        # we may need to update the dist of unexplored successors \n",
      "        for w in G[v]:                          # successors to v\n",
      "            if w in U:                          # then w is a frontier node\n",
      "                d = D[v] + G[v][w]              # dgs: dist of start -> v -> w\n",
      "                if d < Q.get(w, inf):\n",
      "                    Q[w] = d                    # set/update dgs\n",
      "                    P[w] = v                    # set/update predecessor\n",
      "\n",
      "    return D, P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shortest_path(G, start, end):\n",
      "    dist, pred = dijkstra(G, start, end)\n",
      "    v = end\n",
      "    path = [v]\n",
      "    while v != start:\n",
      "        v = pred[v]\n",
      "        path.append(v)        \n",
      "    path.reverse()\n",
      "    return path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmap_9=np.zeros((10,4))\n",
      "cmap_9[0,:]=[0.6, 0.6, 0.6, 1]\n",
      "cmap_9[9,:]=[0.8, 0.6151497514677574, 0.11111, 1]\n",
      "cmap_9[2,:]=[0.89573241682613591, 0.76784315109252932, 0.58182240093455595,1]\n",
      "cmap_9[3,:]=[0.86, 0.37119999999999997, 0.34,1]\n",
      "cmap_9[4,:]=[0.9677975592919913, 0.44127456009157356, 0.5358103155058701,1]\n",
      "cmap_9[5,:]=[0.75, 0.4, 0.5,1]\n",
      "cmap_9[6,:]=[0.8616090647292522, 0.536495730113334, 0.19548899031476086,1]\n",
      "cmap_9[7,:]=[0.46810256823426105, 0.6699492535792404, 0.1928958739904499,1]\n",
      "cmap_9[8,:]=[0.20125317221201128, 0.6907920815379025, 0.6,1]\n",
      "cmap_9[1,:]=[0.21044753832183283, 0.55, 0.7,1]\n",
      "#cmap_9[0,:]=[0.0,0.0,0.0,1.0]\n",
      "cmap_255_9=np.zeros_like(cmap_9)\n",
      "for row in range(cmap_9.shape[0]):\n",
      "    cmap_255_9[row]=[np.floor(i * 255) for i in cmap_9[row]]\n",
      "cmap_255_9=cmap_255_9.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub='BP4T'\n",
      "hemi='lh'\n",
      "n_components_embedding=3\n",
      "n_components_kmeans=9\n",
      "smooth='3'\n",
      "\n",
      "data_dir='/scr/ilz3/myelinconnect/final_struct_space/'\n",
      "#func_file=data_dir+'rest1_1_meshsmooth_%s/%s_%s_mid_simple_0.01_rest_%s_smoothdata.vtk'%(smooth, sub, hemi, hemi)\n",
      "t1_file=data_dir+'t1_smooth_1.5_mesh/%s_%s_mid_simple_0.01_t1_smooth1.5_%s.vtk'%(sub, hemi, hemi)\n",
      "#path_file=data_dir+'mesh_decimate/BP4T_lh_0-01_path.1D.roi'\n",
      "#embed_file=data_dir+\"clustering_%s/%s_%s_mid_simple_0.01_rest_%s_smoothdata_embed_%s.csv\"%(smooth, sub, hemi, hemi, str(n_components_embedding))\n",
      "clust_file=data_dir+\"clustering_%s/%s_%s_mid_simple_0.01_rest_%s_smoothdata_embed_%s_kmeans_%s.csv\"%(smooth, sub, hemi, hemi, str(n_components_embedding), str(n_components_kmeans))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vt,ft,dt=read_vtk(t1_file)\n",
      "\n",
      "vertices = vt['val'].astype(np.float64)\n",
      "triangles = ft['val'].astype(np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G={}\n",
      "\n",
      "for vert in range(len(vertices)):\n",
      "    G[str(vert)]={}\n",
      "    n=[]\n",
      "    all_n=[]\n",
      "    for face in range(triangles.shape[0]):\n",
      "        if vert in triangles[face]:\n",
      "            n=list(triangles[face])\n",
      "            n.remove(vert)\n",
      "            [all_n.append(x) for x in n if x not in all_n]\n",
      "    \n",
      "    for neigh in all_n:\n",
      "        dist=0\n",
      "        #src = np.array([vert], dtype=np.int32)\n",
      "        #trg = np.array([neigh], dtype=np.int32)\n",
      "        #dist=gdist.compute_gdist(vertices, triangles, source_indices = src, target_indices= trg)\n",
      "        \n",
      "        src = vertices[vert]\n",
      "        trg = vertices[neigh]   \n",
      "        dist=np.linalg.norm(src-trg)\n",
      "        \n",
      "        G[str(vert)][str(neigh)]=dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path=shortest_path(G,'1439','6210')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clust=np.loadtxt(clust_file)\n",
      "clust=clust.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_brain=np.zeros_like(dt['val'])\n",
      "for i in path:\n",
      "    path_brain[int(i)]=clust[int(i)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=vt['val'][:,0]\n",
      "y=vt['val'][:,1]\n",
      "z=vt['val'][:,2]\n",
      "t=ft['val']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.figure(bgcolor=(1, 1, 1))\n",
      "img = mlab.triangular_mesh(x,y,z,t, scalars=path_brain[:,0], colormap='jet')\n",
      "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
      "img.module_manager.scalar_lut_manager.lut.table = cmap_255_9\n",
      "mlab.draw()\n",
      "mlab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.figure(bgcolor=(1, 1, 1))\n",
      "img = mlab.triangular_mesh(x,y,z,t, scalars=clust, colormap='jet')\n",
      "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
      "img.module_manager.scalar_lut_manager.lut.table = cmap_255_9\n",
      "mlab.draw()\n",
      "mlab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}