{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raid3/huntenburg/workspace/try_openblas/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import gdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pqdict import PQDict\n",
    "from mayavi import mlab\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from vtk_rw import read_vtk, write_vtk\n",
    "from graphs import graph_from_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dijkstra(G, start, end=None):\n",
    "    '''\n",
    "    dijkstra's algorithm determines the length from `start` to every other \n",
    "    vertex in the graph.\n",
    "    The graph argument `G` should be a dict indexed by nodes.  The value \n",
    "    of each item `G[v]` should also a dict indexed by successor nodes.\n",
    "    In other words, for any node `v`, `G[v]` is itself a dict, indexed \n",
    "    by the successors of `v`.  For any directed edge `v -> w`, `G[v][w]` \n",
    "    is the length of the edge from `v` to `w`.\n",
    "        graph = {'a': {'b': 1}, \n",
    "                 'b': {'c': 2, 'b': 5}, \n",
    "                 'c': {'d': 1},\n",
    "                 'd': {}}\n",
    "    Returns two dicts, `dist` and `pred`:\n",
    "        dist, pred = dijkstra(graph, start='a') \n",
    "    \n",
    "    `dist` is a dict mapping each node to its shortest distance from the\n",
    "    specified starting node:\n",
    "        assert dist == {'a': 0, 'c': 3, 'b': 1, 'd': 4}\n",
    "    `pred` is a dict mapping each node to its predecessor node on the\n",
    "    shortest path from the specified starting node:\n",
    "        assert pred == {'b': 'a', 'c': 'b', 'd': 'c'}\n",
    "    \n",
    "    '''\n",
    "    inf = float('inf')\n",
    "    D = {start: 0}          # mapping of nodes to their dist from start\n",
    "    Q = PQDict(D)           # priority queue for tracking min shortest path\n",
    "    P = {}                  # mapping of nodes to their direct predecessors\n",
    "    #U = set(G.keys())       # unexplored nodes\n",
    "    U = set(G.nodes())\n",
    "\n",
    "    while U:                                    # nodes yet to explore\n",
    "        (v, d) = Q.popitem()                    # node w/ min dist d on frontier\n",
    "        D[v] = d                                # est dijkstra greedy score\n",
    "        U.remove(v)                             # remove from unexplored\n",
    "        if v == end: break\n",
    "\n",
    "        # now consider the edges from v with an unexplored head -\n",
    "        # we may need to update the dist of unexplored successors \n",
    "        for w in G[v]:                          # successors to v\n",
    "            if w in U:                          # then w is a frontier node\n",
    "                d = D[v] + G[v][w]              # dgs: dist of start -> v -> w\n",
    "                if d < Q.get(w, inf):\n",
    "                    Q[w] = d                    # set/update dgs\n",
    "                    P[w] = v                    # set/update predecessor\n",
    "\n",
    "    return D, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shortest_path(G, start, end):\n",
    "    dist, pred = dijkstra(G, start, end)\n",
    "    v = end\n",
    "    path = [v]\n",
    "    while v != start:\n",
    "        v = pred[v]\n",
    "        path.append(v)        \n",
    "    path.reverse()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh='/scr/ilz3/myelinconnect/all_data_on_simple_surf/surfs/lowres_rh_d.vtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v,f,d=read_vtk(mesh)\n",
    "vertices = v.astype(np.float64)\n",
    "faces = f.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=graph_from_mesh(vertices, faces, edge_length=True)\n",
    "#G=make_graph(vertices, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path and windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph representation of the surface is used to find the shortest path between the chosen source and target node. For each node on the path a window is created containing all other nodes that lie within a given radius and are closer to this node that to any other node on the path. These single node windows are then combined into a larger window with the chosen width that is sliding along the path (for now with step=1 node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "radius=10\n",
    "width=3\n",
    "source=46644\n",
    "target=59276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=shortest_path(G,source,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dispay all on surface\n",
    "mlab.figure(bgcolor=(1, 1, 1))\n",
    "img = mlab.triangular_mesh(vertices[:,0],vertices[:,1],vertices[:,2],faces,scalars=allwindow_surf, colormap='Blues')\n",
    "#lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "#img.module_manager.scalar_lut_manager.lut.table = cmap_full\n",
    "mlab.view(300,495, 300, np.array([120,100,90]))\n",
    "mlab.draw()\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.save('/scr/ilz3/myelinconnect/all_data_on_simple_surf/path/rh_4664_59276.npy', np.asarray(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each vertex show only those vertices in the sparse matrix, that have a distance < radius\n",
    "# for these give the precise distance\n",
    "inradius_matrix=gdist.local_gdist_matrix(vertices, faces, max_distance=radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get only the vertices that are in a distance < radius to any node in path\n",
    "inradius_path=[]\n",
    "for pnode in path:\n",
    "    inradius_path=list(np.unique(inradius_matrix[:,path].indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make an array with the radius neighbours in columns and the path nodes in rows\n",
    "path_x_neighbours=np.zeros((len(inradius_path), len(path)))\n",
    "for pnode in range(len(path)):\n",
    "    path_x_neighbours[:,pnode]=np.reshape(inradius_matrix[inradius_path,path[pnode]].toarray(),(len(inradius_path),))\n",
    "path_x_neighbours[path_x_neighbours==0]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each vertex in this list, find the node on path it is closest to\n",
    "path_x_neighbours_min=np.zeros((len(inradius_path),1))\n",
    "for nnode in range(len(inradius_path)):\n",
    "    path_x_neighbours_min[nnode]=np.nanargmin(path_x_neighbours[nnode,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for each node on the path, extract those neighbour nodes, that fall into its window\n",
    "windows=[]\n",
    "for pnode in range(len(path)):\n",
    "    window=[path[pnode]]\n",
    "    indices = [i for i, x in enumerate(list(path_x_neighbours_min)) if x == pnode]\n",
    "    [window.append(inradius_path[y]) for y in indices]\n",
    "    windows.append(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine single windows for sliding\n",
    "combined_windows=[]\n",
    "for window in range(len(windows)):\n",
    "    combined_window=[]\n",
    "    for k in range((window-width),(window+width)):\n",
    "        if (k>=0) and (k<=len(windows)-1):\n",
    "            combined_window+=windows[k]\n",
    "    combined_windows.append(combined_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get windows back to surface space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a full surface for each window, with only the window nodes set to 1\n",
    "window_surfs=[]\n",
    "for combined_window in range(len(combined_windows)):\n",
    "    window_surf=np.zeros((len(vertices),))\n",
    "\n",
    "    for j in path:\n",
    "        window_surf[j]=1\n",
    "        \n",
    "    for i in combined_windows[combined_window]:\n",
    "        window_surf[i]=100\n",
    "    window_surfs.append(window_surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct single surface with all windows differently carrying a different number\n",
    "allwindow_surf=np.zeros((len(vertices),))\n",
    "for window in range(len(windows)):\n",
    "        \n",
    "    for i in windows[window]:\n",
    "        allwindow_surf[i]=window+2\n",
    "        \n",
    "#    for j in path:\n",
    "#        allwindow_surf[j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathbrain=np.zeros_like(vertices[:,0])\n",
    "pathbrain[path]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the all window surface to vtk\n",
    "#write_vtk(outmesh, vertices, faces, np.reshape(allwindow_surf, (allwindow_surf.shape[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/traits/has_traits.py:1928: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  setattr( self, name, value )\n",
      "/usr/lib/python2.7/dist-packages/mayavi/tools/camera.py:276: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if focalpoint is not None and not focalpoint == 'auto':\n"
     ]
    }
   ],
   "source": [
    "# dispay all on surface\n",
    "mlab.figure(bgcolor=(1, 1, 1))\n",
    "img = mlab.triangular_mesh(vertices[:,0],vertices[:,1],vertices[:,2],faces,scalars=allwindow_surf, colormap='Blues')\n",
    "#lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "#img.module_manager.scalar_lut_manager.lut.table = cmap_full\n",
    "mlab.view(300,495, 300, np.array([120,100,90]))\n",
    "mlab.draw()\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# dispay windows moving on surface\n",
    "mlab.figure(bgcolor=(1, 1, 1))\n",
    "img = mlab.triangular_mesh(vertices[:,0],vertices[:,1],vertices[:,2],faces,scalars=window_surfs[0], colormap='gist_gray')\n",
    "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "img.module_manager.scalar_lut_manager.lut.table = cmap\n",
    "mlab.view(300,495, 300, np.array([120,100,90]))\n",
    "mlab.draw()\n",
    "for j in range(len(window_surfs)):\n",
    "    img.mlab_source.scalars = window_surfs[j]\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from plotting import plot_surf_stat_map\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "surf_1 = plot_surf_stat_map(vertices, faces, stat_map=window_surfs[0], elev=-160, azim=180, \n",
    "                          threshold=0.5, cmap='Spectral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "surf_2 = plot_surf_stat_map(vertices, faces, stat_map=window_surfs[20], elev=-160, azim=180, \n",
    "                          threshold=0.5, cmap='Spectral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "surf_3 = plot_surf_stat_map(vertices, faces, stat_map=window_surfs[40], elev=-160, azim=180, \n",
    "                          threshold=0.5, cmap='Spectral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "surf_4 = plot_surf_stat_map(vertices, faces, stat_map=window_surfs[-1], elev=-160, azim=180, \n",
    "                          threshold=0.5, cmap='Spectral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rest='/scr/ilz3/myelinconnect/final_struct_space/rest1_1_meshsmooth_3/BP4T_lh_mid_simple_0.01_rest_lh_smoothdata.vtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv, rf, rd=read_vtk(rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pearsonr in sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is calculated for all nodes. Within each window the correlation vectors are averaged (after Fisher r-to-z transform). The Pearson correlation of the resulting average vectors (after z-to-r transform) is used as a measure of similarity between the connectivity profiles of adjacent windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate correlation matrix\n",
    "R=np.nan_to_num(np.corrcoef(rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r-to-z transform for averaging\n",
    "Z=np.arctanh(R)\n",
    "# sample corrvectors per window and average\n",
    "#corr_windows=[]\n",
    "corr_avgs=[]\n",
    "for window in combined_windows:\n",
    "    corr_window=Z[window]\n",
    "    corr_avg_z=np.mean(corr_window, 0)\n",
    "    corr_avg_r=np.tanh(corr_avg_z)\n",
    "    #corr_windows.append(corr_window)\n",
    "    corr_avgs.append(corr_avg_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_corr_avgs=[]\n",
    "p_corr_avgs=[]\n",
    "for vec in range(len(corr_avgs)-1):\n",
    "    r,p=stats.pearsonr(corr_avgs[vec], corr_avgs[vec+1])\n",
    "    r_corr_avgs.append(r)\n",
    "    p_corr_avgs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.plot(r_corr_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_window_R=R[combined_windows[3]]\n",
    "test_window_Z=Z[combined_windows[3]]\n",
    "plt.plot(test_window_R[0,:], color='red', alpha=0.3, label='R')\n",
    "plt.plot(test_window_Z[0,:], color='blue', alpha=0.3, label='Z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_window_R_avg=np.mean(test_window_R, 0)\n",
    "test_window_Z_avg=np.mean(test_window_Z, 0)\n",
    "test_window_Z_avg_toR=np.tanh(test_window_Z_avg)\n",
    "plt.plot(test_window_R_avg, color='red', alpha=0.3, label='Ravg')\n",
    "#plot(test_window_Z_avg, color='blue', alpha=0.3, label='Zavg')\n",
    "plt.plot(test_window_Z_avg_toR, color='green', alpha=0.3, label='Zavg2R')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eta square and comparison along the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eta square is an alternative measure to compare the average connectivity profiles across windows. Unlike Pearson correlation it is also sensitive to scaling and offsets (see below). In Cohen 2008 eta square is not only compared in adjacent parts of a path but along the full path to find abrupt changes. Here, eta square is first implemented for the sliding windows and then for the full path. Moreover, the full path approach is tested for the Pearson correlation as a similarity measure, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohen Neuroimage 2008:\n",
    "\"eta 2 is equal to the fraction of the variance in one signal accounted for by variance in a second signal where comparisons are done on a point by point basis. The more similar two signals, or in this case, images, are the higher the eta 2 coefficient between them. eta 2 can vary in value from 0 (no similarity) to 1 (identical).\"\n",
    "\"We use eta 2 to compare images instead of correlation, r, because our goal is to quantify the difference or similarity of the two images, not the correlational relationship between them. While correlation is often used for similarity description, there are instances where the correlation coefficient between images is unaffected by changes in the two images which make them more or less similar from each other. Two examples where this is readily apparent are scaling and offset;\"\n",
    "\"To objectively separate the eta 2 profiles into groups hierarchical clustering analysis was performed on the eta 2 profiles to find any strong divisions among the set\"\n",
    "\"While there is a general decrease in eta 2 coefficient with distance from the comparison point, abrupt changes are concentrated at specific locations along the line regardless of which initial comparison points are chosen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple eta square calc in sliding windows\n",
    "eta2_list=[]\n",
    "for i in range(len(corr_avgs)-1):\n",
    "    a=corr_avgs[i]\n",
    "    b=corr_avgs[i+1]\n",
    "    m=np.mean(np.vstack((a,b)),0) # mean vector\n",
    "    M=np.mean(m) # grand mean across both vectors\n",
    "\n",
    "    SSwithin=0\n",
    "    SStotal=0\n",
    "    eta2=0\n",
    "    for node in range(a.shape[0]):\n",
    "        ssw=np.power((a[node]-m[node]),2)+np.power((b[node]-m[node]),2)\n",
    "        sst=np.power((a[node]-M),2)+np.power((b[node]-M),2)\n",
    "        SSwithin+=ssw\n",
    "        SStotal+=sst\n",
    "    eta2=1-(SSwithin/SStotal)\n",
    "    eta2_list.append(eta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.plot(r_corr_avgs, alpha=0.7, label='pearsonr')\n",
    "plt.plot(eta2_list, color='brown', alpha=0.7, label='eta2')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# eta square across the full path length\n",
    "def etasquare(correlation_vectors):\n",
    "    \n",
    "    eta2_array=np.zeros((len(correlation_vectors), len(correlation_vectors)))\n",
    "    for i in range(len(correlation_vectors)):\n",
    "        for j in range(len(correlation_vectors)):\n",
    "            a=correlation_vectors[i]\n",
    "            b=correlation_vectors[j]\n",
    "            m=np.mean(np.vstack((a,b)),0) # mean vector\n",
    "            M=np.mean(m) # grand mean across both vectors\n",
    "    \n",
    "            SSwithin=0\n",
    "            SStotal=0\n",
    "            eta2=0\n",
    "            for node in range(a.shape[0]):\n",
    "                ssw=np.power((a[node]-m[node]),2)+np.power((b[node]-m[node]),2)\n",
    "                sst=np.power((a[node]-M),2)+np.power((b[node]-M),2)\n",
    "                SSwithin+=ssw\n",
    "                SStotal+=sst\n",
    "            eta2=1-(SSwithin/SStotal)\n",
    "            eta2_array[i,j]=eta2\n",
    "    return eta2_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eta2_windows=etasquare(corr_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#same approach for correlations\n",
    "def corrcorr(correlation_vectors):\n",
    "    \n",
    "    corrcorr_array=np.zeros((len(correlation_vectors), len(correlation_vectors)))\n",
    "    for i in range(len(correlation_vectors)):\n",
    "        for j in range(len(correlation_vectors)):                      \n",
    "            a=correlation_vectors[i]\n",
    "            b=correlation_vectors[j]\n",
    "            r,p=stats.pearsonr(a,b)\n",
    "            corrcorr_array[i,j]=r\n",
    "    return corrcorr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrcorr_windows=corrcorr(corr_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting\n",
    "etamap=np.array(sns.diverging_palette(220, 20, n=61, center='dark'))\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "#ax=fig.add_subplot(1,1,1)\n",
    "#for w in range(len(eta2_windows)):\n",
    "#    r=etamap[w][0]\n",
    "#    g=etamap[w][1]\n",
    "#    b=etamap[w][2]\n",
    "#    ax.plot(eta2_windows[w], color=(r,g,b), label='eta2 '+str(w))\n",
    "#plt.xlabel('window', fontsize=20)\n",
    "#plt.ylabel('eta2', fontsize=20)\n",
    "#ylim((-0.4,1))\n",
    "\n",
    "ax2=fig.add_subplot(1,1,1)\n",
    "for w in range(len(corrcorr_windows)):\n",
    "    r=etamap[w][0]\n",
    "    g=etamap[w][1]\n",
    "    b=etamap[w][2]\n",
    "    ax2.plot(corrcorr_windows[w], color=(r,g,b), label='eta2 '+str(w))\n",
    "plt.xlabel('Window', fontsize=30)\n",
    "plt.ylabel(\"Pearson's r\", fontsize=30)\n",
    "plt.ylim((-0.4,1))\n",
    "\n",
    "sns.palplot(sns.diverging_palette(220, 20, n=10, center='dark'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t1 average values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first approach to assessing T1 difference along the path, for each node the average cortical T1 value, excluding outer and innermost layers (=layer 3to7 of 11) to reduce partial volume effects, is sampled. For each window the mean and variance are calculated and compared along the path. In principal, peak variances could indicate aprupt changes in the T1 pattern. However, the average T1 value is a very rough measure to describe cortical architecture and using the shape of the T1 profiles across the cortex (see below) might be the better approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1='/scr/ilz3/myelinconnect/final_struct_space/t1_smooth_1.5_mesh/BP4T_lh_mid_simple_0.01_t1_smooth1.5_lh.vtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv, tf, td =read_vtk(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample t1 per window, calc mean and variance\n",
    "t1_windows=[]\n",
    "t1_means=[]\n",
    "t1_vars=[]\n",
    "for window in combined_windows:\n",
    "    t1_window=td[window]\n",
    "    t1_mean=t1_window.mean()\n",
    "    t1_var=t1_window.var()\n",
    "    \n",
    "    t1_windows.append(t1_window)\n",
    "    t1_means.append(t1_mean)\n",
    "    t1_vars.append(t1_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1plot_list=[]\n",
    "for n in range(len(t1_windows)):\n",
    "    t1plot_list+=[np.reshape(t1_windows[n], (t1_windows[n].shape[0],))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.set_context('notebook', font_scale=1.5)\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "\n",
    "t1=fig.add_subplot(4,1,1)\n",
    "sns.violinplot(t1plot_list)\n",
    "sns.axlabel('','T1', fontsize=20)\n",
    "\n",
    "t1mean=fig.add_subplot(4,1,2)\n",
    "plt.plot(t1_means)\n",
    "t1mean.set_xlim([0, len(windows)])\n",
    "t1mean.set_xticks(range(0, len(combined_windows), 2))\n",
    "sns.axlabel('','T1 mean', fontsize=20)\n",
    "\n",
    "t1var=fig.add_subplot(4,1,3)\n",
    "plt.plot(t1_vars)\n",
    "t1var.set_xlim([0,len(windows)])\n",
    "t1var.set_xticks(range(0, len(combined_windows), 2))\n",
    "sns.axlabel('','T1 var', fontsize=20)\n",
    "\n",
    "corr=fig.add_subplot(4,1,4)\n",
    "plt.plot(r_corr_avgs)\n",
    "corr.set_xlim([0,len(windows)])\n",
    "corr.set_xticks(range(0, len(combined_windows), 2))\n",
    "sns.axlabel('','corr', fontsize=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# dispay high variance windows\n",
    "mlab.figure(bgcolor=(1, 1, 1))\n",
    "img = mlab.triangular_mesh(vertices[:,0],vertices[:,1],vertices[:,2],faces,scalars=window_surfs[10], colormap='gist_gray')\n",
    "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
    "img.module_manager.scalar_lut_manager.lut.table = cmap\n",
    "mlab.view(300,495, 300, np.array([120,100,90]))\n",
    "mlab.draw()\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# dispay high variance windows\n",
    "mlab.figure(bgcolor=(1, 1, 1))\n",
    "img = mlab.triangular_mesh(vertices[:,0],vertices[:,1],vertices[:,2],faces,scalars=np.reshape(td, td.shape[0],), vmin=1800)\n",
    "mlab.view(300,495, 300, np.array([120,100,90]))\n",
    "mlab.draw()\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t1 profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average T1 profiles per window are approximated using Chebychev polynomials. The resulting coefficients are used as a feature vector to assess the distance between windows. As opposed to the features used in the observer-independent parcellation approach in Schleicher, Neuroimage 1999 this accounts for the actual geometric shape of the profile instead of interpreting them as frequency curves.  To quantify the distance between adjacent windows, the Jensen-Shannon divergence of the SSQ between the coefficient vectors is calculated. This statistic is preferable to the Hotteling test as the latter has a high false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1_profiles='/scr/ilz3/myelinconnect/working_dir/profile_sampling/exp-0000/exp-0000-A/SurfaceMeshMapping/BP4T_lh_mid_simple_0.01_profiles.vtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profv, proff, profd =read_vtk(t1_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average profiles within windows\n",
    "prof_avgs=[]\n",
    "for window in combined_windows:\n",
    "    prof_window=profd[window]\n",
    "    prof_avg=np.mean(prof_window, 0)\n",
    "    prof_avgs.append(prof_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=30\n",
    "x=np.array(range(len(prof_avgs[w])))\n",
    "#y=prof_avgs[w]\n",
    "y=profd[345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation with Chebychev polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cheb5=np.polynomial.chebyshev.chebfit(x, y, 5)\n",
    "cheb10=np.polynomial.chebyshev.chebfit(x, y, 10)\n",
    "cheb20=np.polynomial.chebyshev.chebfit(x, y, 20)\n",
    "cheb30=np.polynomial.chebyshev.chebfit(x, y, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y, label='orig')\n",
    "plt.plot(np.polynomial.chebyshev.chebval(x, cheb5), color='green',label='cheb 5', linestyle='None', marker='o', markersize=10, alpha=0.5)\n",
    "plt.plot(np.polynomial.chebyshev.chebval(x, cheb10), color='black', label='cheb 10', linestyle='None', marker='o', markersize=10, alpha=0.5)\n",
    "plt.plot(np.polynomial.chebyshev.chebval(x, cheb20), color='blue', label='cheb 20', linestyle='None', marker='o', markersize=10, alpha=0.5)\n",
    "plt.plot(np.polynomial.chebyshev.chebval(x, cheb30), color='red', label='cheb 30', linestyle='None', marker='o', markersize=10, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('Approximation with Chebychev polynomials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cheb5, color='green',label='cheb 5', alpha=0.5)\n",
    "plt.plot(cheb10, color='black', label='cheb 10', alpha=0.5)\n",
    "plt.plot(cheb20, color='blue', label='cheb 20', alpha=0.5)\n",
    "plt.plot(cheb30, color='red', label='cheb 30', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(-300,300)\n",
    "plt.title('Chebychev coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chebapprox(profiles, degree):\n",
    "    profiles=np.array(profiles)\n",
    "    cheb_coeffs=np.zeros((profiles.shape[0],degree+1))\n",
    "    cheb_polynoms=np.zeros((profiles.shape[0],profiles.shape[1]))\n",
    "    for c in range(profiles.shape[0]):\n",
    "        x=np.array(range(profiles.shape[1]))\n",
    "        y=profiles[c]\n",
    "        cheb_coeffs[c]=np.polynomial.chebyshev.chebfit(x, y, degree)\n",
    "        cheb_polynoms[c]=np.polynomial.chebyshev.chebval(x, cheb_coeffs[c])\n",
    "    return cheb_coeffs, cheb_polynoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cheb_coeffs, cheb_polynoms=chebapprox(prof_avgs, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=figure(figsize(10,10))\n",
    "for c in range(cheb_polynoms.shape[0]):\n",
    "    r=etamap[c][0]\n",
    "    g=etamap[c][1]\n",
    "    b=etamap[c][2]\n",
    "    plt.plot(cheb_polynoms[c], color=(r,g,b,0.6))\n",
    "plt.xlabel('window', fontsize=15)\n",
    "plt.ylabel('T1', fontsize=15)\n",
    "sns.palplot(sns.diverging_palette(220, 20, n=12, center='dark'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### euclidian distance between chebychev coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "euclid_list=[]\n",
    "for w in range(len(combined_windows)-1):\n",
    "    diff=sp.spatial.distance.euclidean(cheb_coeffs[w],cheb_coeffs[w+1])\n",
    "    euclid_list.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale=1.5)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "euclidplot=fig.add_subplot(2,1,1)\n",
    "plt.plot(euclid_list)\n",
    "euclidplot.set_xlim([0, len(windows)])\n",
    "euclidplot.set_xticks(range(0, len(combined_windows), 2))\n",
    "sns.axlabel('','euclidian distance \\nchebychev coefficients', fontsize=20)\n",
    "\n",
    "corr=fig.add_subplot(2,1,2)\n",
    "plt.plot(r_corr_avgs)\n",
    "corr.set_xlim([0,len(windows)])\n",
    "corr.set_xticks(range(0, len(combined_windows), 2))\n",
    "sns.axlabel('','corr', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclid(coeffs):\n",
    "    euclid_array=np.zeros((coeffs.shape[0], coeffs.shape[0]))\n",
    "    for i in range(coeffs.shape[0]):\n",
    "        for j in range(coeffs.shape[0]):\n",
    "            euclid_array[i,j]=sp.spatial.distance.euclidean(cheb_coeffs[i],cheb_coeffs[j])\n",
    "    return euclid_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "euclid_windows=euclid(cheb_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting\n",
    "etamap=np.array(sns.diverging_palette(245, 10, n=61, center='dark'))\n",
    "fig=plt.figure(figsize=(15,10))\n",
    "ax=fig.add_subplot(2,1,1)\n",
    "for s in range(len(euclid_windows)):\n",
    "    r=etamap[s][0]\n",
    "    g=etamap[s][1]\n",
    "    b=etamap[s][2]\n",
    "    ax.plot(euclid_windows[s], color=(r,g,b))\n",
    "plt.xlabel('window', fontsize=15)\n",
    "plt.ylabel('euclidian distance \\nchebychev coefficients', fontsize=15)\n",
    "\n",
    "sns.palplot(sns.diverging_palette(245, 10, n=17, center='dark'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons with Jensen-Shannon divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jensen-Shannon divergence measures the similarity of two probability functions, roughly the amount of information lost when one function is approximated by the other. It is derived from the Kullback-Leibler divergence however as compared to that has the advantage of being symmetric and always finite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapted from \n",
    "stackoverflow http://stats.stackexchange.com/questions/29578/jensen-shannon-divergence-calculation-for-3-prob-distributions-is-this-ok\n",
    "& scipy open PR https://github.com/scipy/scipy/pull/3213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# @author: jonathanfriedman\n",
    "\n",
    "def jensenshannon(x,y): #Jensen-shannon divergence\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    x=x/x.sum()\n",
    "    y=y/y.sum()\n",
    "    m = (x + y)/2.\n",
    "    m = np.where(m,m,1.)\n",
    "    d1 = x*np.log2(2*x/m)\n",
    "    d2 = y*np.log2(2*y/m)\n",
    "    d1[np.isnan(d1)] = 0\n",
    "    d2[np.isnan(d2)] = 0\n",
    "    d = 0.5*np.sum(d1+d2)    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next steps / questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* implement different overlap of windows\n",
    "* t1 avg profiles or coefficients? comparing profiles or coefficients?\n",
    "* js\n",
    "* degree of chebychev?\n",
    "* Is non-independence of overlapping windows addressed? Is the overlap a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
