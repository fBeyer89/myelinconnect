{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import gdist\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "'''\n",
      "Functions to read and write vtk files\n",
      "------------------------------------\n",
      "* read takes vtk file and returns vertex and face array\n",
      "* write takes vertex and faces array and optional comment and returns vtk file\n",
      "* reading and writing of texture not supported yet\n",
      "\n",
      "TO DO: add reading comments\n",
      "'''\n",
      "\n",
      "def read_vtk(file):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    # read full file while dropping empty lines \n",
      "    vtk_df=pd.read_csv(file, header=None)\n",
      "    vtk_df=vtk_df.dropna()\n",
      "    # extract number of vertices and faces\n",
      "    number_vertices=int(vtk_df[vtk_df[0].str.contains('POINTS')][0].iloc[0].split()[1])\n",
      "    number_faces=int(vtk_df[vtk_df[0].str.contains('POLYGONS')][0].iloc[0].split()[1])\n",
      "    # read vertices into df and array\n",
      "    start_vertices= (vtk_df[vtk_df[0].str.contains('POINTS')].index.tolist()[0])+1\n",
      "    vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=number_vertices, sep='\\s*', header=None)\n",
      "    if np.array(vertex_df).shape[1]==3:\n",
      "        vertex_array=np.array(vertex_df)\n",
      "    # sometimes the vtk format is weird with 9 indices per line, then it has to be reshaped\n",
      "    elif np.array(vertex_df).shape[1]==9:\n",
      "        vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=int(number_vertices/3+1), sep='\\s*', header=None)\n",
      "        vertex_array=np.array(vertex_df.iloc[0:1,0:3])\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,3:6], axis=0)\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,6:9], axis=0)\n",
      "        for row in range(1,int(number_vertices/3+1)):\n",
      "            for col in [0,3,6]:\n",
      "                vertex_array=np.append(vertex_array, array(vertex_df.iloc[row:(row+1),col:(col+3)]),axis=0) \n",
      "        # strip rows containing nans\n",
      "        vertex_array=vertex_array[ ~np.isnan(vertex_array) ].reshape(number_vertices,3)\n",
      "    else:\n",
      "        print \"vertex indices out of shape\"\n",
      "    # read faces into df and array\n",
      "    start_faces= (vtk_df[vtk_df[0].str.contains('POLYGONS')].index.tolist()[0])+1\n",
      "    face_df=pd.read_csv(file, skiprows=range(start_faces), nrows=number_faces, sep='\\s*', header=None)\n",
      "    face_array=np.array(face_df.iloc[:,1:4])\n",
      "    # read data into df and array if exists\n",
      "    if vtk_df[vtk_df[0].str.contains('POINT_DATA')].index.tolist()!=[]:\n",
      "        start_data=(vtk_df[vtk_df[0].str.contains('POINT_DATA')].index.tolist()[0])+3\n",
      "        number_data = number_vertices\n",
      "        data_df=pd.read_csv(file, skiprows=range(start_data), nrows=number_data, sep='\\s*', header=None)\n",
      "        data_array=np.array(data_df)\n",
      "    else:\n",
      "        data_array = np.empty(0)\n",
      "    \n",
      "    return vertex_array, face_array, data_array\n",
      "\n",
      "\n",
      "\n",
      "def write_vtk(filename, vertices, faces, data=None, comment=None):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    # infer number of vertices and faces\n",
      "    number_vertices=vertices.shape[0]\n",
      "    number_faces=faces.shape[0]\n",
      "    if data is not None:\n",
      "        number_data=data.shape[0]\n",
      "    # make header and subheader dataframe\n",
      "    header=['# vtk DataFile Version 3.0',\n",
      "            '%s'%comment,\n",
      "            'ASCII',\n",
      "            'DATASET POLYDATA',\n",
      "            'POINTS %i float'%number_vertices\n",
      "             ]\n",
      "    header_df=pd.DataFrame(header)\n",
      "    sub_header=['POLYGONS %i %i'%(number_faces, 4*number_faces)]\n",
      "    sub_header_df=pd.DataFrame(sub_header)    \n",
      "    # make dataframe from vertices\n",
      "    vertex_df=pd.DataFrame(vertices)\n",
      "    # make dataframe from faces, appending first row of 3's (indicating the polygons are triangles)\n",
      "    triangles=np.reshape(3*(np.ones(number_faces)), (number_faces,1))\n",
      "    triangles=triangles.astype(int)\n",
      "    faces=faces.astype(int)\n",
      "    faces_df=pd.DataFrame(np.concatenate((triangles,faces),axis=1))\n",
      "    # write dfs to csv\n",
      "    header_df.to_csv(filename, header=None, index=False)\n",
      "    with open(filename, 'a') as f:\n",
      "        vertex_df.to_csv(f, header=False, index=False, float_format='%.3f', sep=' ')\n",
      "    with open(filename, 'a') as f:\n",
      "        sub_header_df.to_csv(f, header=False, index=False)\n",
      "    with open(filename, 'a') as f:\n",
      "        faces_df.to_csv(f, header=False, index=False, float_format='%.0f', sep=' ')\n",
      "    # if there is data append second subheader and data\n",
      "    if data!=None:\n",
      "        datapoints=data.shape[1]\n",
      "        sub_header2=['POINT_DATA %i'%(number_data),\n",
      "                     'SCALARS EmbedVertex float %i'%(datapoints),\n",
      "                     'LOOKUP_TABLE default']\n",
      "        sub_header_df2=pd.DataFrame(sub_header2)\n",
      "        data_df=pd.DataFrame(data)\n",
      "        with open(filename, 'a') as f:\n",
      "            sub_header_df2.to_csv(f, header=False, index=False)\n",
      "        with open(filename, 'a') as f:\n",
      "            data_df.to_csv(f, header=False, index=False, float_format='%.16f', sep=' ')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "v,f,d = read_vtk('/scr/ilz3/myelinconnect/groupavg/highres_rh.vtk')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sv, sf, sd = read_vtk('/scr/ilz3/myelinconnect/groupavg/lowres_rh_c.vtk')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sv = sv[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v.shape[0]/sv.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "9.085872283004141"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for each vertex in the simplified mesh, find the closest vertex in the highres mesh\n",
      "mapping = []\n",
      "for lowres_idx in range(sv.shape[0]):\n",
      "    dist = 10000\n",
      "    closest = None\n",
      "    for highres_idx in range(v.shape[0]):\n",
      "        d = sqrt((v[highres_idx][0] - sv[lowres_idx][0]) ** 2 \n",
      "                 + (v[highres_idx][1] - sv[lowres_idx][1]) ** 2 \n",
      "                 + (v[highres_idx][2] - sv[lowres_idx][2]) ** 2)\n",
      "        if d < dist:\n",
      "            dist = d\n",
      "            closest = highres_idx\n",
      "    mapping.append([lowres_idx, closest])\n",
      "mapping = np.asarray(mapping) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10):\n",
      "    print sv[mapping[i][0]]\n",
      "    print v[mapping[i][1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  62.893  120.216  140.334]\n",
        "[  62.9978  120.181   140.329 ]\n",
        "[  56.286  124.307  139.362]\n",
        "[  56.3508  124.389   139.351 ]\n",
        "[  56.705  124.635  139.435]\n",
        "[  56.7053  124.635   139.435 ]\n",
        "[  56.925  124.812  139.325]\n",
        "[  56.925  124.812  139.325]\n",
        "[  57.926  123.762  139.26 ]\n",
        "[  57.8548  123.806   139.268 ]\n",
        "[  57.669  123.472  139.294]\n",
        "[  57.6693  123.472   139.294 ]\n",
        "[  57.279  123.151  139.356]\n",
        "[  57.3364  123.297   139.349 ]\n",
        "[  56.292  122.727  139.441]\n",
        "[  56.2492  122.66    139.401 ]\n",
        "[  60.042  119.146  139.541]\n",
        "[  60.1939  119.05    139.586 ]\n",
        "[  64.205  118.404  140.49 ]\n",
        "[  64.0536  118.319   140.437 ]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for each vertex on the highres mesh find all nodes in a given radius\n",
      "radius = 5\n",
      "vertices = v.astype(np.float64)\n",
      "faces = f.astype(np.int32)\n",
      "inradius_matrix=gdist.local_gdist_matrix(vertices, faces, max_distance=radius)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for each vertex in the highres mesh find that node that corresponds to one on the lowres mesh and is closest\n",
      "for highres_idx in range(v.shape[0]):\n",
      "    inradius_matrix[v[highres_idx]].indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}