{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%gui wx\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "load libraries, functions, colormap"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as stats\n",
      "import matplotlib.pyplot as plt\n",
      "from mayavi import mlab\n",
      "from sklearn.utils.arpack import eigsh\n",
      "from sklearn.cluster import KMeans\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/nose/util.py:14: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
        "  from compiler.consts import CO_GENERATOR\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "this version of read_vtk only works if there is data attached to the nodes, need to make it optional"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_vtk(file):\n",
      "    # read full file while dropping empty lines \n",
      "    vtk_df=pd.read_csv(file, header=None)\n",
      "    vtk_df=vtk_df.dropna()\n",
      "    # extract number of vertices and faces\n",
      "    number_vertices=int(vtk_df[vtk_df[0].str.contains('POINTS')][0].iloc[0].split()[1])\n",
      "    number_faces=int(vtk_df[vtk_df[0].str.contains('POLYGONS')][0].iloc[0].split()[1])\n",
      "    # read vertices into df and array\n",
      "    start_vertices= (vtk_df[vtk_df[0].str.contains('POINTS')].index.tolist()[0])+1\n",
      "    vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=number_vertices, sep='\\s*', header=None)\n",
      "    if np.array(vertex_df).shape[1]==3:\n",
      "        vertex_array=np.array(vertex_df)\n",
      "    # sometimes the vtk format is weird with 9 indices per line, then it has to be reshaped\n",
      "    elif np.array(vertex_df).shape[1]==9:\n",
      "        vertex_df=pd.read_csv(file, skiprows=range(start_vertices), nrows=number_vertices/3+1, sep='\\s*', header=None)\n",
      "        vertex_array=np.array(vertex_df.iloc[0:1,0:3])\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,3:6], axis=0)\n",
      "        vertex_array=np.append(vertex_array, vertex_df.iloc[0:1,6:9], axis=0)\n",
      "        for row in range(1,(number_vertices/3+1)):\n",
      "            for col in [0,3,6]:\n",
      "                vertex_array=np.append(vertex_array, array(vertex_df.iloc[row:(row+1),col:(col+3)]),axis=0) \n",
      "        # strip rows containing nans\n",
      "        vertex_array=vertex_array[ ~np.isnan(vertex_array) ].reshape(number_vertices,3)\n",
      "    else:\n",
      "        print \"vertex indices out of shape\"\n",
      "    vertices = {'val' : vertex_array, 'number' : number_vertices}\n",
      "    # read faces into df and array\n",
      "    start_faces= (vtk_df[vtk_df[0].str.contains('POLYGONS')].index.tolist()[0])+1\n",
      "    face_df=pd.read_csv(file, skiprows=range(start_faces), nrows=number_faces, sep='\\s*', header=None)\n",
      "    face_array=np.array(face_df.iloc[:,1:4])\n",
      "    faces = {'val' : face_array, 'number' : number_faces}\n",
      "    # read data into df and array\n",
      "    start_data= (vtk_df[vtk_df[0].str.contains('POINT_DATA')].index.tolist()[0])+3\n",
      "    number_data = number_vertices\n",
      "    data_df=pd.read_csv(file, skiprows=range(start_data), nrows=number_data, sep='\\s*', header=None)\n",
      "    data_array=np.array(data_df)\n",
      "    data = {'val' : data_array, 'number' : number_data}\n",
      "    \n",
      "    return vertices, faces, data\n",
      "\n",
      "#TO DO: add reading comments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "cmap created with sns.palplot(sns.color_palette(\"Set2\", 7)), then adding grey in the beginning. For use with mayavi transformed to array, added alpha value and multiply all by 255"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmap=np.zeros((8,4))\n",
      "cmap[0,:]=[0.6, 0.6, 0.6, 1]\n",
      "cmap[1,:]=[0.40000000596046448, 0.7607843279838562, 0.64705884456634521, 1]\n",
      "cmap[2,:]=[0.98131487965583808, 0.55538641635109398, 0.38740485135246722,1]\n",
      "cmap[3,:]=[0.55432528607985565, 0.62711267120697922, 0.79595541393055635,1]\n",
      "cmap[4,:]=[0.90311419262605563, 0.54185316071790801, 0.76495195557089413,1]\n",
      "cmap[5,:]=[0.65371782148585622, 0.84708959004458262, 0.32827375098770734,1]\n",
      "cmap[6,:]=[0.9986312957370983, 0.85096502233954041, 0.18488274134841617,1]\n",
      "cmap[7,:]=[0.89573241682613591, 0.76784315109252932, 0.58182240093455595,1]\n",
      "cmap_255=np.zeros_like(cmap)\n",
      "for row in range(cmap.shape[0]):\n",
      "    cmap_255[row]=[np.floor(i * 255) for i in cmap[row]]\n",
      "cmap_255=cmap_255.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "load relevant files for subject and hemisphere"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub='OL1T'\n",
      "hemi='rh'\n",
      "n_components_embedding=3\n",
      "n_components_kmeans=7\n",
      "smooth='meshsmooth_3'\n",
      "data_dir='/scr/ilz3/myelinconnect/final_struct_space/'\n",
      "#func_file=data_dir+'rest1_1_%s/%s_%s_mid_simple_0.01_rest_%s_smoothdata.vtk'%(smooth, sub, hemi, hemi)\n",
      "t1_file=data_dir+'t1_smooth_1.5_mesh/%s_%s_mid_simple_0.01_t1_smooth1.5_%s.vtk'%(sub, hemi, hemi)\n",
      "embed_file=data_dir+\"clustering/%s_%s_mid_simple_0.01_rest_%s_smoothdata_embed_%s.csv\"%(sub, hemi, hemi, str(n_components_embedding))\n",
      "clust_file=data_dir+\"clustering/%s_%s_mid_simple_0.01_rest_%s_smoothdata_embed_%s_kmeans_%s_subclust.csv\"%(sub, hemi, hemi, str(n_components_embedding), str(n_components_kmeans))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vt,ft,dt=read_vtk(t1_file)\n",
      "t1=dt['val'][:,0]\n",
      "\n",
      "embed=np.loadtxt(embed_file, delimiter=',')\n",
      "clust=np.loadtxt(clust_file, delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/pandas/io/parsers.py:624: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
        "  ParserWarning)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "look at clustering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xt=vt['val'][:,0]\n",
      "yt=vt['val'][:,1]\n",
      "zt=vt['val'][:,2]\n",
      "trianglest=ft['val']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cmap from 0 to 7 to detect relevant clusters\n",
      "sns.palplot(cmap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAABGCAYAAABBh6SMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAfFJREFUeJzt1zFKnFEYheE7IVlEVmBrY5dsIZWFWgXEsReyCuEnTYr8\nEJhKmywi4HTTpB1IqxauIFjcNGkjJ5CbT/F52suF0718i957bwDAg15UDwCAp0AwASAgmAAQEEwA\nCAgmAAQEEwB+u15/+uPby4c+zvP8z8c8Fsvlsp1eXVTPGObz26N2Px1Xzxjm1dmXNq021TOGOHu/\n16bVph3e/ayeMsTrD2/a7fm6fXv3sXrKEIc7X9vldr8dtB/VU4ZY7Hxvfbvbbu5Oqqf8dy5MAAgI\nJgAEBBMAAoIJAAHBBICAYAJAQDABICCYABAQTAAICCYABAQTAAKCCQABwQSAgGACQEAwASAgmAAQ\nEEwACAgmAAQEEwACggkAAcEEgIBgAkBAMAEgIJgAEBBMAAgIJgAEBBMAAoIJAAHBBICAYAJAQDAB\nICCYABAQTAAICCYABAQTAAKCCQABwQSAgGACQEAwASAgmAAQEEwACAgmAAQEEwACggkAAcEEgIBg\nAkBAMAEgIJgAEBBMAAgIJgAEBBMAAoIJAAHBBICAYAJA4NkGc57n6glDnV5dVE8Y6n46rp4wzLTa\nVE8Y6vZ8XT1hqMvtfvWEofp2t3pCmUXvvVePAIDH7tlemADwNwQTAAKCCQABwQSAgGACQEAwASDw\nC65ANpZKW3sDAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x9946e50>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.figure(bgcolor=(1, 1, 1))\n",
      "img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=clust[:,0], colormap='hsv')\n",
      "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
      "img.module_manager.scalar_lut_manager.lut.table = cmap_255\n",
      "mlab.draw()\n",
      "mlab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/traits/has_traits.py:1928: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
        "  setattr( self, name, value )\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "decide on cluster of interest, neighbour and relevant subcluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster=4\n",
      "neighbour=1\n",
      "\n",
      "coi=clust[:,cluster+1]\n",
      "neigh=clust[:,neighbour+1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "in this case better not to use the colormap which is restricted to 8 colors as there might be more subclusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.figure(bgcolor=(1, 1, 1))\n",
      "img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=coi, colormap='hsv')\n",
      "#img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=neigh, colormap='hsv')\n",
      "#lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
      "#img.module_manager.scalar_lut_manager.lut.table = cmap_255\n",
      "mlab.draw()\n",
      "mlab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "to get an idea of how many clusters there are"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print clust[:,cluster+1].max()\n",
      "print clust[:,neighbour+1].max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6.0\n",
        "16.0\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub_cluster=6\n",
      "sub_cluster2=4\n",
      "sub_neighbour=15"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coi_sub=np.zeros_like(coi)\n",
      "coi_sub[coi == sub_cluster] = 1\n",
      "\n",
      "coi_sub2=np.zeros_like(coi)\n",
      "coi_sub2[coi == sub_cluster2] = 1\n",
      "\n",
      "neigh_sub=np.zeros_like(neigh)\n",
      "neigh_sub[neigh == sub_neighbour] = 1\n",
      "\n",
      "all_sub=np.zeros_like(coi)\n",
      "all_sub[coi == sub_cluster] = 1\n",
      "all_sub[coi == sub_cluster2] = 1\n",
      "all_sub[neigh == sub_neighbour] = 7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.figure(bgcolor=(1, 1, 1))\n",
      "#img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=coi_sub, colormap='hsv')\n",
      "#img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=coi_sub2, colormap='hsv')\n",
      "#img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=neigh_sub, colormap='hsv')\n",
      "img = mlab.triangular_mesh(xt,yt,zt,trianglest,scalars=all_sub, colormap='hsv')\n",
      "lut = img.module_manager.scalar_lut_manager.lut.table.to_array()\n",
      "img.module_manager.scalar_lut_manager.lut.table = cmap_255\n",
      "mlab.draw()\n",
      "mlab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "get t1 values within all subclusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a list of dictionaries for each cluster k0, k1, ...(0=mask to max kmeans) \n",
      "# and subcluster s0_1, s1_1, s1_2, ..(1 to max subcluster, no 0 subcluster)\n",
      "t1_clust={}\n",
      "for c in range(int(clust[:,0].max()+1)):\n",
      "    t1_clust['k'+str(c)]=[]\n",
      "    for s in range(int(clust[:,c+1].max())):\n",
      "        t1_clust['s'+str(c)+'_'+str(s+1)]=[]\n",
      "\n",
      "# write all t1 values in one cluster into the list of its dictionary\n",
      "for i in range(len(t1)):\n",
      "    if t1[i]>1000:\n",
      "        k=int(clust[:,0][i])\n",
      "        sub=int(clust[:,(k+1)][i])\n",
      "        t1_clust['k'+str(k)].append(t1[i])\n",
      "        t1_clust['s'+str(k)+'_'+str(sub)].append(t1[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "compare variances when adding different subclusters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The levene test is more robust than the F test for different sample sizes and non-normally distributed data. \n",
      "In particular the variation after Brown & Forsythe using the deviation from the median (instead of mean) as used here. \n",
      "\n",
      "A p-value (second output) below a given alpha (e.g. 0.05) indicates the variances of the two samples are significantly different from each other."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1_cluster=t1_clust['k'+str(cluster)]\n",
      "t1_neighbour=t1_clust['k'+str(neighbour)]\n",
      "t1_sub_cluster=t1_clust['s'+str(cluster)+'_'+str(sub_cluster)]\n",
      "t1_sub_cluster2=t1_clust['s'+str(cluster)+'_'+str(sub_cluster2)]\n",
      "t1_sub_neighbour=t1_clust['s'+str(neighbour)+'_'+str(sub_neighbour)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'sub_cluster vs sub_cluster+sub_cluster2', stats.levene(t1_sub_cluster, (t1_sub_cluster+t1_sub_cluster2))\n",
      "print 'sub_cluster vs sub_cluster+sub_neighbour', stats.levene(t1_sub_cluster, (t1_sub_cluster+t1_sub_neighbour))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sub_cluster vs sub_cluster+sub_cluster2 (19.60474763193524, 1.1828034359915484e-05)\n",
        "sub_cluster vs sub_cluster+sub_neighbour (0.010498159525079544, 0.91844366920039755)\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'sub_cluster vs cluster', stats.levene(t1_sub_cluster, t1_cluster)\n",
      "print 'sub_neighbour vs neighbour', stats.levene(t1_sub_neighbour, t1_neighbour)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sub_cluster vs cluster (31.223712783080927, 2.8883167330943229e-08)\n",
        "sub_neighbour vs neighbour (13.744342353627772, 0.00021918980446672984)\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}